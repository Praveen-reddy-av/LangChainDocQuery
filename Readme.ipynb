{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858c6ff0",
   "metadata": {},
   "source": [
    "# LangChainDocQuery\n",
    "\n",
    "LangChainDocQuery is an intelligent document querying system that leverages OpenAI's language models, embeddings, and a vector store backed by Cassandra. It allows users to input natural language questions and retrieve relevant text snippets from PDF documents.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Extract text from PDF documents\n",
    "- Split text into manageable chunks\n",
    "- Generate embeddings for text chunks\n",
    "- Store embeddings in a Cassandra-backed vector store\n",
    "- Query the stored text using natural language questions\n",
    "- Retrieve and display relevant text snippets based on semantic similarity\n",
    "\n",
    "## Installation\n",
    "\n",
    "1. Clone the repository:\n",
    "    ```sh\n",
    "    git clone https://github.com/yourusername/LangChainDocQuery.git\n",
    "    cd LangChainDocQuery\n",
    "    ```\n",
    "\n",
    "2. Install the required dependencies:\n",
    "    ```sh\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "3. Set up your environment variables:\n",
    "    - `ASTRA_DB_APPLICATION_TOKEN`: Your Astra DB application token\n",
    "    - `ASTRA_DB_ID`: Your Astra DB ID\n",
    "    - `OPENAI_API_KEY`: Your OpenAI API key\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Place your PDF file in the project directory and update the file path in the script.\n",
    "2. Run the script to extract text from the PDF, generate embeddings, and store them in the Cassandra-backed vector store:\n",
    "    ```sh\n",
    "    python main.py\n",
    "    ```\n",
    "\n",
    "3. Start the querying interface to input natural language questions and retrieve relevant text snippets:\n",
    "    ```sh\n",
    "    python query_interface.py\n",
    "    ```\n",
    "\n",
    "## Example Code\n",
    "\n",
    "```python\n",
    "# provide the path of the PDF file\n",
    "pdf_path = 'GOT.pdf'\n",
    "\n",
    "# Initialize the connection to your database\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
    "\n",
    "# Create LangChain embedding and LLM objects\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Create Cassandra vector store\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")\n",
    "\n",
    "# Split the text using CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Add texts to the vector store\n",
    "astra_vector_store.add_texts(texts[:50])\n",
    "\n",
    "# Initialize the vector store index wrapper\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "\n",
    "# Start the query loop\n",
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        q_text = input(\"\\nEnter the question(or q to quit): \").strip()\n",
    "        first_question = False\n",
    "    else:\n",
    "        q_text = input(\"\\nEnter another question(or q to quit): \").strip()\n",
    "\n",
    "    if q_text.lower() == 'q':\n",
    "        break\n",
    "\n",
    "    answer = astra_vector_index.query(q_text, llm=llm).strip()\n",
    "    print(f\"\"\"\n",
    "    question: \"{q_text}\"\n",
    "    answer: \"{answer}\"\n",
    "    \n",
    "    Documents for relevance\n",
    "    \"\"\")\n",
    "    \n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(q_text, k=4):\n",
    "        print(f\"   [{score:.4f}] \\\"{doc.page_content[:80]}...\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8c546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
